{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7649a2b5",
   "metadata": {},
   "source": [
    "<center><img width=\"25%\" src=\"https://www.camaramirimdoce.sc.gov.br/media/noticia/resumo-da-sessao-10-06-2019-111.png?w=848&h=450&t=P&c=f0f0f0&q=80&v=2\"></center>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "# Ciências de Dados\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1753ae6",
   "metadata": {},
   "source": [
    "# **Sumário:**\n",
    "1. [Introdução](#Introdução)\n",
    "2. [Biblioteca NumPy e Pandas](#Biblioteca-NumPy-e-Pandas)\n",
    "3. [Introdução a Estatística](#Introdução-a-Estatística)\n",
    "4. [Biblioteca Matplotlib](#Biblioteca-Matplotlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6077a6",
   "metadata": {},
   "source": [
    "### **Introdução** \n",
    "[&#x1F53C;](#Sumário:) Clique para voltar para o sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580de72e",
   "metadata": {},
   "source": [
    "#### Conceito: É o processo de exploração, manipulação e análise dos dados para a descoberta e previsão, através da criação de hipóteses, testes e validação (Embasamento estatístico e matemático) com o objetivo de responder perguntas do negócio e/ou fazer recomendações capazes de serem diferenciais de negócio, além de poder ser feito de forma escalável e replicável. \n",
    "<br>\n",
    "\n",
    "#### > Inteligência (Conhecimento aplicado, analise para tomada de decisão) \n",
    "#### > Conhecimento (Informação após a interpretação, requer análise, entendimento, avaliação e contexto) \n",
    "#### > Informações (Dados processados, com contexto e significado, possuem relevância e proposito)  \n",
    "#### > Dados (Armazenamento, Processamento e Visualização. Informações brutas, registros de ocorrência, observações.)\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Existe um método científico: Observação → Hipóteses → Experimento (Teste, validação e monitoramento) → Análise/Resultado → Conclusão.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Framework (Conjuntos de passos) = CRISP-DM (CROSS INDUSTRY STANDARD PROCESS FOR DATA MINING):\n",
    "##### Entendimento do negócio → Entendimento dos dados → Engenharia de dados (Caso esteja faltando os dados) → Preparação dos dados → Análise/Modelagem → Validação → Preparação / Visualização\n",
    "\n",
    "* Entendimento do negócio: Definição do problema + Alinhamento de expectativas (Previsão de Erros, Prazos, se é viável ou não, Indicadores, Definição do que é o \"pronto\") \n",
    "* Entendimento dos dados \n",
    "* Engenharia de dados (Busca/Coleta de dados faltantaes > Saber como fazer as inúmeras formas de busca) \n",
    "    * Abra o prompt de comando do Anaconda\n",
    "    * Entrar na pasta do projeto: UTilizando o comando cd\n",
    "    * Criar o Ambiente Virtual --> conda create -n \"nome do meu ambiente\" python (Só precisa fazer esse passo uma única vez)\n",
    "    * Ativar o Ambiente Virtual --> conda activate \"nome do meu ambiente\"\n",
    "    * Instalação do IDE --> py -m pip install jupyter\n",
    "    * Abrindo o IDE --> py -m jupyter notebook\n",
    "    * Instalação as bibliotecas necessárias no Ambiente Virtual\n",
    "        * Abra outro pront de comando do Anaconda e ative o Ambiente Virtual\n",
    "        * conda install pip ou conda install \"Biblioteca\"\n",
    "        * pip install \"Biblioteca\"\n",
    "    * Reinicie o IDE\n",
    "    * Importe a base para o python\n",
    "* Preparação dos dados: Realização de um pré-processamento, como validar se os dados vieram corretos, se as frequências que recebemos os dados está sendo suficientes, se existe dados corrompidos, valores vazios, com tipos incorretos, saber quais são as fontes e formatos, se recebemos todos os dados, quais colunas ou bases não poderemos considerar. (Power Query – Linguagem M) > Limpeza\n",
    "* Análise/Modelagem: \n",
    "    * Analise exploratória (Entendemos as relações, limites, outliers, tendências e padrões - Respondendo as perguntas) \n",
    "    * Tratamento dos dados (Os dados já estão no modelo e já foram analisados de forma exploratória, com isso podemos incluir novas colunas, criar variáveis explicativas, selecionar variáveis, criar agrupamentos, combinações e derivações dos dados. Utilizar técnicas para normalizar valores, tratar valores discrepantes, não deixar que informações escalares afetem o modelo, retirar ruídos desnecessários. (Power BI – Linguagem DAX)) \n",
    "    * Definição do modelo (Conjunto de regras para realizar determinada ação para solucionar o problema de negócio)\n",
    "* Validação do modelo (Validar o modelo com outros valores) \n",
    "* Preparação / Visualização: Análise Explanatória (Entendemos as conclusões, evidências e sofisticação) e a realização de uma checagem/Feedback com o cliente (Implementação do modelo X Voltar ao entendimento do negócio) + Apresentação do resultado: Gráficos, emails, relatários\n",
    "    * Criação de Dashboard (Comparado ao que? Bom ou Ruim? / Melhores e Piores? Métricas corretas? Tem apenas um tema? Tamanho, Resolução, Proporção, excesso ou falta de níveis)\n",
    "    * 7 elementos em cada Dashboard\n",
    "    * 20 linhas em cada gráfico\n",
    "    * Formas de organizar a informação (Localização, alfabeticamente, tempo, categoria e hierarquia)\n",
    "* Melhoria contínua, monitoramento e ajustes no modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a648892",
   "metadata": {},
   "source": [
    "### **Biblioteca NumPy e Pandas** \n",
    "[&#x1F53C;](#Sumário:) Clique para voltar para o sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50981610",
   "metadata": {},
   "source": [
    "#### O Pandas é a biblioteca inicial do processo de Ciencia de Dados. \n",
    "* Os DataFrames lembram o Excel e é usado desde a importação da base até a criação do modelo, incluindo a análise e visuallização dos dados, tratamentos, agregações, etc.\n",
    "* Instalação da biblioteca: pip install pandas\n",
    "* Cada coluna em uma Dataframe é um Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40840f5b",
   "metadata": {},
   "source": [
    "##### Importação do Pandas\n",
    "> import pandas as pd\n",
    "\n",
    "##### Leitura de dados tabulares (Extensões: csv, xlsx, html, hdf5, json, gbq, sql, parquet, etc)\n",
    "> dataframe = pd.read_extensoes(r'Caminho/arquivo.extensao')\n",
    "\n",
    "##### Gravação de dados tabulares (Extensões: csv, xlsx, html, hdf5, json, gbq, sql, parquet, etc)\n",
    "> pd.to_extensoes(r'Caminho/arquivo.extensao')\n",
    "\n",
    "##### Transformando um dicionário em DataFrame\n",
    "> dataframe = pd.DataFrame(dict) <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "\n",
    "##### Transformando uma coluna em DataFrame em Series\n",
    "> series = dataframe['NomeDaColuna']\n",
    "> Com os valores da coluna >>> series.values\n",
    "> Com os valores dos indices >>> series.index\n",
    "\n",
    "##### Verificando o tipo de dado\n",
    "> Tipo de cada coluna >>> dataframe.dtypes <br> \n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html <br>>\n",
    "> Tipo do objeto >>> type(dataframe)  \n",
    "\n",
    "##### Visualização do DataFrame\n",
    "> 5 primeiras linhas >>> dataframe.head() <br> \n",
    "> Nr primeiras linhas >>> dataframe.head(Nr) <br>\n",
    "> 5 últimas linhas >>> dataframe.tail() <br>\n",
    "> Nr últimas linhas >>> dataframe.tail(Nr) <br>\n",
    "> Algums colunas >>> dataframe[['NomeDaColunaA', 'NomeDaColunaZ']] <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html\n",
    "\n",
    "##### Informações do DataFrame\n",
    "> dataframe.info() <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html\n",
    "\n",
    "##### Filtrando apenas alguns dados\n",
    "> dataframe[ FiltroDaLinha, FiltraDaColuna] ou dataframe.loc[ FiltroDaLinha, FiltraDaColuna ]  ou dataframe.iloc[ IndiceDaLinha, IndiceDaColuna ]<br>\n",
    "> FiltroDaLinha >>> dataframe[Coluna] OperadorDeComparação Nr (Ex: [base['Salario'] > 1000), ['NomeDaColuna',...] ou :) <br>\n",
    "> FiltroDaColuna >>> dataframe[Coluna] OperadorDeComparação Nr (Ex: Vazio ou :, [base['Salario'] > 1000]) <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html\n",
    "\n",
    "##### Operações matemática de agregação\n",
    "> Média: dataframe[NomeDaColuna].mean() <br>\n",
    "> Mínimo: dataframe[NomeDaColuna].min() <br>\n",
    "> Máximo: dataframe[NomeDaColuna].max() <br>\n",
    "> Contagem: dataframe[NomeDaColuna].count() <br>\n",
    "> Mediana: dataframe[NomeDaColuna].median() <br>\n",
    "> Desvio padrão: dataframe[NomeDaColuna].std() \n",
    "\n",
    "##### Contando os valores vazios de cada coluna (True = 1 e False = 0)\n",
    "> dataframe.isnull().sum() <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html\n",
    "\n",
    "##### Contando os valores que não estão vazios de cada coluna (True = 1 e False = 0)\n",
    "> dataframe.notnull().sum() <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notnull.html\n",
    "\n",
    "##### Contando os valores de uma coluna\n",
    "> dataframe[NomeDaColuna].value_counts() <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html\n",
    "\n",
    "##### Exibe um resumo estatístico de cada coluna numérica\n",
    "> dataframe.describe() <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\n",
    "\n",
    "##### Exclusão de linhas ou colunas\n",
    "> Excluir coluna >>> dataframe.drop(NomeDaColuna, axis=1, inplace=True) (Ex: Excluir a coluna A: dataframe = dataframe.drop('ColunaA', axis=1, inplace=True) <br>\n",
    "> Excluir várias colunas >>> dataframe.drop({Lista de Colunas}, axis=1, inplace=True) (Ex: Excluir as colunas A e B: dataframe.drop({'ColunaA', 'ColunaB'}, axis=1, inplace=True)) <br>\n",
    "> Excluir linha >>> dataframe.drop(Nr_Indice, axis=0, inplace=True) (Ex: Excluir a linha de indice 1: dataframe = dataframe.drop(1, axis=0, inplace=True)) <br>\n",
    "> Excluir várias linhas >>> dataframe.drop([Lista de indices], axis=0, inplace=True) (Ex: Excluir as linhas de indices 1 e 2: dataframe = dataframe.drop([1,2], axis=0, inplace=True)) <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html\n",
    "\n",
    "##### Renomear de linhas ou colunas \n",
    "> Renomear linha >>> dataframe.rename(index=None, columns=None, axis=None, inplace=False) (Ex: Renomear a linha 1: dataframe.rename(index={1:'NomeNovo'}, axis=0, inplace=True) <br>\n",
    "> Renomear coluna >>> dataframe.rename(index=None, columns=None, axis=None, inplace=False) (Ex: Renomear a coluna A: dataframe.rename(columns={'ColunaA':'NomeNovo'}, axis=1, inplace=True) <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html\n",
    "\n",
    "##### Ordenar pela linha ou pela coluna\n",
    "> Linha >>> dataframe.sort_values(by=Indice, axis=0, ascending=True, inplace=False, ignore_index=False) <br>\n",
    "> Coluna >>> dataframe.sort_values(by='NomeDaColuna', axis=1, ascending=True, inplace=False, ignore_index=False)\n",
    "* ascending=True >>> Ordem crescente\n",
    "* ascending=False >>> Ordem decrescente\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html\n",
    "\n",
    "##### Agrupamento de colunas ou linhas\n",
    "> dataframe.groupby(by='NomeDaColunaLinha', axis=0 ou 1, sort=True, dropna=True) <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html <br>\n",
    "> Agregar por 1 coluna ou linha >>> dataframe.groupby(by='NomeDaColunaAgrupada')['NomeDaColunaAfetadaPelaFunção'].função_agregação() <br>\n",
    "> Agregar por mais de 1 coluna ou linha >>> dataframe.groupby(by='ListaDeColunasOuLinhasAgrupadas')[['ListaDeColunasAfetadasPelaFunção']].função_agregação()\n",
    "* sort=True >>> Ordem crescente\n",
    "* dropna=True >>> Os valores NA juntamente com a linha/coluna serão descartados\n",
    "\n",
    "##### Variação dos resultados apos agrupamento, em porcentagem\n",
    "> dataframe.groupby(by='NomeDaColunaAgrupada')['NomeDaColunaAfetadaPelaFunção'].função_agregação().pct_change() * 100 <br>\n",
    "> Variação Percentual = ((Valor Atual - Valor Anterior) / Valor Anterior) * 100 <br>\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a2d8b2",
   "metadata": {},
   "source": [
    "#### O NumPy é a principal biblioteca de computação numérica do Python, otimizada para cálculos pesados e serve de base para o Pandas.\n",
    "* No NumPy tranalha-se com arrays, que são estruturas de dados multidimensionais (1D, 2D, 3D), trabalham com dados do mesmo tipo, são mutáveis, ordenados e possuem comprimentos variáveis\n",
    "* Instalação da biblioteca: pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa2d20",
   "metadata": {},
   "source": [
    "##### Importação do Pandas\n",
    "> import numpy as np\n",
    "\n",
    "##### Transformando uma lista em um array\n",
    "> np.array(lista)\n",
    "\n",
    "##### Verificando o tipo de dado\n",
    "> Tipo de cada dado >>> array.dtype <br>\n",
    "> Tipo do objeto >>> type(array)\n",
    "\n",
    "##### Operações básicas\n",
    "> Soma 2 arrays >>> array + array <br>\n",
    "> Soma todos os dados >>> array.sum() <br>\n",
    "> Soma apenas os dados das linhas >>> array.sum(axis=1) <br>\n",
    "> Soma apenas os dados das colunas >>> array.sum(axis=0) <br>\n",
    "> Soma acumulada dos dados das linhas >>> array.cumsum(axis=1) <br>\n",
    "> Soma de um nr com todos os dados >>> array + Nr <br>\n",
    "> Subtração >>> array - array <br>\n",
    "> Subtração de um nr com todos os dados >>> array - Nr <br>\n",
    "> Multiplicação >>> array * array <br>\n",
    "> Multiplicação de um nr com todos os dados >>> array * Nr <br>\n",
    "> Divisão >>> array / array\n",
    "> Potência >>> array ** array\n",
    "\n",
    "##### Criando array utilizando Range\n",
    "> Uma dimensão (Vetor) >>> np.arange(nr_inicial, nr_final, nr_passo) <br>\n",
    "> Duas dimensões (Matriz) >>> np.arange(nr_inicial, nr_final, nr_passo).reshape(qtde_linhas, qtde_colunas)\n",
    "\n",
    "##### Verificando a dimensão  do array\n",
    "> array.ndim\n",
    "\n",
    "##### Verificando a quantidade de linhas e colunas do array\n",
    "> array.shape\n",
    "\n",
    "##### Criando array utilizando números inteiros e decimais\n",
    "> np.array([numeros,...])\n",
    "\n",
    "##### Criando array apenas com valores zero ou um\n",
    "> np.zeros(qtde_zero) <br>\n",
    "> np.ones(qtde_um)\n",
    "\n",
    "##### Criando array com número inicial, final e a quantidade de dados (Igualmente espaçados)\n",
    "> np.linspace(nr_inicial, nr_final, qtde)\n",
    "\n",
    "##### Filtrando apenas alguns dados\n",
    "> array[indice da linha][indice da coluna] (Ex: array[Nr][Nr]) <br>\n",
    "> array[Filtro] <br>\n",
    "> Filtro >>> array OperadorDeComparação Nr (Ex: [array >,<,=,!= Nr]) <br> \n",
    "> Filtro >>> (array OperadorDeComparação Nr) OperadorLógico (array OperadorDeComparação Nr) (Ex: [array >,<,=,!= Nr] &,I [array >,<,=,!= Nr])] \n",
    "\n",
    "##### Operações matemática de agregação\n",
    "> Mínimo das linhas >>> array.min(axis=1) <br> \n",
    "> Mínimo das colunas >>> array.min(axis=0) <br> \n",
    "> Mínimo de todos os dados >>> array.min() <br> \n",
    "> Máximo das linhas >>> array.max(axis=1) <br> \n",
    "> Máximo das colunas >>> array.max(axis=0) <br> \n",
    "> Máximo de todos os dados >>> array.max() <br> \n",
    "> Média das linhas >>> array.mean(axis=1) <br> \n",
    "> Média das colunas >>> array.mean(axis=0) <br> \n",
    "> Média apenas da primeira linha >>> array[0].mean() ou array.mean(axis=1)[0] <br>\n",
    "> Mediana de todos os dados >>> np.median(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be69b7",
   "metadata": {},
   "source": [
    "### **Introdução a Estatística** \n",
    "[&#x1F53C;](#Sumário:) Clique para voltar para o sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a59a2",
   "metadata": {},
   "source": [
    "#### O que é? \n",
    "* Coleta, Organização, Apresentação, Interpretação e Análise\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Estatística descritiva: Descrição e apresentação dos dados de forma a facilitar o entendimento de um grande conjunto de dados. Fornece um resumo sobre os dados apresentados, podendo ser visual (tabelas de frequência, histogramas, gráficos) ou quantitativo (média, mediana e moda) <br>\n",
    "\n",
    "#### Tabela de Frequência: \n",
    "* Apresenta os dados e a quantidade de ocorrências / repetições daquele dado.\n",
    "    \n",
    "        pd.crosstab(index=df.Coluna, columns='contagem')\n",
    "        \n",
    "* Serve para a visualização e entedimento de grandes conjuntos de dados.\n",
    "* Exibição gráfica de uma distribuição de frequência: Histograma.\n",
    "        \n",
    "        df.Coluna.hist()\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Resumo estatístivo: É uma forma de apresentar os principais conceitos sobre a distribuição dos dados de forma resumida, usando para isso: \n",
    "* Média: É basicamente a posição central de determinado conjunto de dados. É alterada por outliers.\n",
    "* Mediana: É o valor central de um conjunto de dados ordenados. \n",
    "* Moda: Valor mais frequente do conjunto de dados. A moda será afetada se a quantidade de dados adicionados for suficiente para fazer com que um dado seja o mais frequente.\n",
    "* Desvio Padrão\n",
    "###### Média X Mediana: \n",
    "* A mediana será afetada pela quantidade de dados adicionado na base.\n",
    "* A média será afetada pelo valor dos dados adicionados na base.\n",
    "* A média pode ser utilizada para analisar uma variável em relação a outra (Evitar outliers utilizando um limitador de valor). Podemos usar a média e os outliers para identificação de fraudes.\n",
    "* A mediana pode ser utilizada para analisar o tempo de uma variável."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ad36d9",
   "metadata": {},
   "source": [
    "### **Biblioteca Matplotlib** \n",
    "[&#x1F53C;](#Sumário:) Clique para voltar para o sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ab62e",
   "metadata": {},
   "source": [
    "####  Permite a criação de visualizações estáticas mais simples até os gráficos mais complexos e elaborados. \n",
    "* Pyplot é o módulo do Matplotlib que possui os gráficos básicos\n",
    "* Documentação: https://matplotlib.org/\n",
    "* Instalação da biblioteca >>> pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c895f83",
   "metadata": {},
   "source": [
    "#### Importação do Matplotlib\n",
    "> import matplotlib.pyplot as plt\n",
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d369e8",
   "metadata": {},
   "source": [
    "DATA SCIENCE\n",
    "O QUE É DATA SCIENCE\n",
    "A ciência de dados tem a mesma função do BI dentro de uma empresa, no entanto, a abordagem utilizada para a interpretação desses dados é diferente. Aqui, temos a presença de um profissional multidisciplinar conhecido como o cientista de dados.\n",
    "Dentre as suas especialidades estão a matemática, a estatística, a programação e o conhecimento básico acerca do negócio, já que ele deverá analisar as informações com base no que a empresa espera descobrir.\n",
    "Por meio da análise de um conjunto específico de dados coletados junto à empresa, o cientista de dados se utiliza de métodos científicos para analisar e gerar conhecimentos valiosos para a organização, por meio da exploração de padrões e anomalias no conjunto de informações coletadas.\n",
    "Principais aplicações do Data Science.\n",
    "Assim como no BI, o Data Science tem como principal objetivo auxiliar o gestor a identificar determinadas oportunidades ou riscos para as operações, sendo assim tomado como uma atividade estratégica para o desenvolvimento do negócio.\n",
    "No entanto, o Data Science é muito mais flexível, podendo ser utilizado para avaliar e verificar as ocorrências dentro de conjuntos de dados internos e externos da empresa, podendo analisar riscos e oportunidades fora do ambiente do negócio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa802b2",
   "metadata": {},
   "source": [
    "CIÊNCIA DOS DADOS | DATA SCIENCE\n",
    "O que é cientista de dados? O que os cientistas de dados fazem? Os cientistas de dados combinam estatística, matemática, programação, resolução de problemas para capturar dados de maneiras engenhosas, com capacidade de olhar os dados de forma diferente para encontrar padrões, juntamente com as atividades de limpeza, preparação e organização dos dados. Esses dados podem ser Estruturados e Não-Estruturados.\n",
    "Simplificando, Data Science é um campo que abrange qualquer coisa relacionada à limpeza, preparação e análise de dados. É um termo abrangente para as técnicas utilizadas a fim de se extrair dados e obter insights através de informações (conjunto de dados).\n",
    "CIÊNCIA DE DADOS – CONHECIMENTO NECESSÁRIO\n",
    "•\tConhecimento aprofundado de SAS e / ou R. Para Data Science, R é geralmente preferido.\n",
    "•\tCodificação Python: Python é a linguagem de codificação mais comum que é usado na ciência dos dados, juntamente com Java, Perl, C / C ++.\n",
    "•\tPlataforma Hadoop: Embora nem sempre seja um requisito, é importante saber que a plataforma Hadoop é preferida para a área. A experiência em Hive ou Pig é uma grande vantagem.\n",
    "•\tBanco de dados / codificação SQL: Embora o NoSQL e o Hadoop sejam o foco principal para cientistas de dados, os candidatos preferenciais podem escrever e executar consultas complexas em SQL.\n",
    "•\tTrabalhando com dados não estruturados: é extremamente importante que um Cientista de Dados possa trabalhar com dados não estruturados, seja de mídias sociais, feeds de vídeo, áudio ou outras fontes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45921b00",
   "metadata": {},
   "source": [
    "DATA SCIENCE\n",
    "Dentro da empresa, a Ciência de Dados tem a mesma finalidade que o Business Intelligence – converter dados brutos em insights de negócios que os líderes empresariais e gestores possam usar para tomar decisões baseadas em dados. As empresas viram a disponibilidade de grandes volumes de dados como fonte de vantagem competitiva. As empresas que conseguem utilizar esses dados de forma eficaz tomam melhores decisões e estão à frente da curva de crescimento. Para dar sentido a tais dados, surgiu a necessidade de um novo conjunto de habilidades que incluísse a habilidade para definir e compreender problemas de negócio, habilidades analíticas, habilidades de programação, habilidades estatísticas, habilidades de aprendizado de máquina, visualização de dados e muito mais.\n",
    "Isso levou ao surgimento do papel de um Cientista de Dados. Se a empresa possui grandes conjuntos de dados estruturados e não estruturados que podem ou não estar completos e sendo necessário converter essas fontes em informações valiosas para apoio à decisão, então a empresa deve recorrer a um Cientista de Dados. Ciência de dados centrada em negócio é multidisciplinar e integra os seguintes elementos:\n",
    "Análise Quantitativa – modelagem matemática, análise estatística, previsões e simulações.\n",
    "Habilidades em Programação – habilidades em programação para analisar dados brutos e torná-los acessíveis aos usuários de negócio.\n",
    "Conhecimento do Negócio – conhecimento do ambiente de negócio, para melhor compreender a relevância dos resultados encontrados.\n",
    "Ciência de Dados é uma disciplina pioneira. Cientistas de Dados muitas vezes empregam o método científico para a exploração de dados, formação de hipóteses e testes de hipóteses (através de simulação e modelagem estatística). Cientistas de Dados com foco de negócios geram conhecimentos valiosos, muitas vezes, explorando padrões e anomalias em dados de negócios. Ciência de Dados em um contexto de negócios é comumente composta de:\n",
    "Conjuntos de dados internos e externos – A Ciência de Dados é flexível. Você pode criar dados corporativos MASHUPS a partir de fontes internas e externas de dados estruturados e não estruturados com bastante facilidade (DADOS MASHUP é uma combinação de duas ou mais fontes de dados, que são analisadas em conjunto, a fim de fornecer aos usuários uma visão mais completa da situação em foco).\n",
    "Tecnologias e ferramentas – Exemplos aqui poderiam envolver o uso de plataformas baseadas em nuvem, programação matemática, estatística e de aprendizado de máquina, análise de dados utilizando Python, R, Java ou Scala e de visualização avançada de dados.\n",
    "Você pode usar a Ciência de Dados para obter insights de negócios a partir de conjuntos de tamanho padrão de dados de negócios estruturados (assim como BI) ou a partir de conjuntos estruturados, semi-estruturados, não estruturados e Big Data. Soluções de Ciências de Dados não se limitam aos dados transacionais; você pode usar a ciência para criar valiosos insights de todas as fontes de dados disponíveis. Essas fontes de dados incluem:\n",
    "Dados Transacionais – Uma fonte de dados de negócio transacional é o mesmo tipo de dados estruturados utilizados em BI tradicional e inclui dados de gerenciamento, atendimento ao cliente, vendas e dados de marketing, dados operacionais e dados de desempenho do empregado.\n",
    "Dados de Mídias Sociais – dados não estruturados gerados a partir de e-mails, fóruns, blogs e redes sociais como Twitter, Facebook, LinkedIn, Pinterest e Instagram.\n",
    "Dados de Máquinas e Operações de Negócio – dados não estruturados gerados automaticamente por máquinas, tal como dados de sensores de automóveis, por exemplo.\n",
    "Dados de áudio, video, imagem e arquivos pdf – fontes de dados comuns e bem estabelecidas.\n",
    "Uma vez que os produtos da Ciência de Dados muitas vezes são gerados a partir de Big Data, soluções de plataformas de dados baseadas em nuvem são comuns neste campo. Os dados que são usados na Ciência de Dados são frequentemente derivados de soluções como Hadoop, MapReduce, Spark e processamento paralelo. Cientistas de Dados devem possuir visão inovadora e devem pensar fora da caixa, a fim de buscar soluções para os problemas que resolvem. Muitos Cientistas de Dados tendem para o uso de ferramentas open-source, quando disponíveis. A partir de uma perspectiva de custo, esta abordagem beneficia as organizações que empregam esses cientistas.\n",
    "Cientistas de Dados com foco em negócios podem usar técnicas de aprendizado de máquina (Machine Learning) para encontrar padrões e obter insights de grandes conjuntos de dados que estão relacionados com uma linha de negócio específica ou o negócio em geral. Eles são qualificados em matemática, estatística e programação, e usam essas habilidades para gerar modelos preditivos. Eles geralmente sabem como programar em Python, R, Java ou Scala. A maioria deles sabe como usar SQL para consultar dados relevantes.\n",
    "\n",
    "Um Cientista de Dados deve ter um forte senso de negócios e a capacidade de comunicar efetivamente conclusões baseadas em dados para os tomadores de decisão das empresas. Um Cientista de Dados não apenas abordará problemas de negócios, ele também escolherá os problemas certos que tenham mais valor para a organização. O trabalho de um Analista de BI é encontrar padrões e tendências nos dados históricos de uma organização. Enquanto o BI seja amplamente baseado na exploração de tendências passadas, a Ciência de Dados consiste em encontrar preditores e o significado dessas tendências. Assim, o objetivo principal de um Analista de BI é avaliar o impacto de certos eventos nas operações cotidianas de uma empresa ou comparar o desempenho de uma empresa com o de outras empresas no mesmo mercado. O Cientista de Dados é encarregado de avaliar como esses eventos impactam o futuro da empresa!\n",
    "E as ferramentas que ambos utilizam também são diferentes, já que Analistas de BI e Cientistas de Dados possuem objetivos diferentes a partir da análise de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d471312",
   "metadata": {},
   "source": [
    "O Problema de Negócio (As perguntas do CEO)\n",
    "\n",
    "Planejamento da solução\n",
    "\n",
    "Planejamento do Produto Final\n",
    "\tComo vamos entregar as respostas das perguntas de negócio?\n",
    "\t1. Vamos escrever um e-mail?\n",
    "\t2. Vamos enviar uma planilha?\n",
    "\t3. Vamos enviar um gráfico em uma ferramenta de visualização.\n",
    "\t4. Vamos enviar um algoritmo treinado?\n",
    "\n",
    "Planejamento do Processo\n",
    "\tQuais são os passos para encontrar as respostas?\n",
    "\t1. Coletar um conjunto de dados ( planilha de dados )\n",
    "\t2. Manipular os dados\n",
    "\t\t# Faz o carregamento de um arquivo salvo no computador\n",
    "\t\tuploaded = files.upload()\n",
    "\t\tdf = pd.read_csv( io.BytesIO( uploaded['NomeDoArquivo.csv'] ) )\n",
    "\t\tprint( type( df ) ) # verificar o tipo de objeto.\n",
    "\t\t# Mostrar o número de linhas e colunas do cojunto de dados\n",
    "\t\tprint( df.shape )\n",
    "\t\t# Mostrar as 6 primeiras linhas\n",
    "\t\tprint( df.head() )\n",
    "\t\t# Mostrar os tipos das variáveis de cada coluna\n",
    "\t\tprint( df.dtypes() )\n",
    "\t\t# Mostrar o número de NA em cada coluna.\n",
    "\t\tprint( df.isna().sum() )\n",
    "\t\t# Mostrar as estatísticas do conjunto de dados.\n",
    "\t\tprint( df.info() )\n",
    "\t\t# Comando padrão para seleção de colunas\n",
    "\t\t# df.loc[linhas, colunas]\n",
    "\t\t# Selecionando colunas -> cols = ['NomeDaColuna1', 'NomeDaColuna2', 'NomeDaColuna3']\n",
    "\t\t# Selecionando as linhas -> # Vamos usar o símbolo : para selecionar todas as linhas\n",
    "\t\tdf1 = df.loc[:, cols]\n",
    "\t\t# calculando a média\n",
    "\t\tmedia = np.mean( df1 )[0]\n",
    "\t\tprint( media )\n",
    "\t\t# calculando o desvio padrao\n",
    "\t\tdesvio_padrao = np.std( df1 )[0]\n",
    "\t\tprint( desvio_padrao )\n",
    "\t\t# desenhando o gráfico\n",
    "\t\thist = px.histogram( df1[df1['price'] < 2000], x='price', nbins=20 )\n",
    "\t\thist.show()\n",
    "\n",
    "Planejamento das Ferramentas\n",
    "\tQuais as ferramentas que precisamos usar para encontrar as respostas?\n",
    "\t1. Linguagem de programação\n",
    "\t2. Estatística\n",
    "\t3. Ferramenta para usar a linguagem de programação\n",
    "\n",
    "Respondendo as perguntas de negócio\n",
    "Mais perguntas do CEO\n",
    "\n",
    "Exemplos:\n",
    "\n",
    "# Qual é o valor do aluguel (diária) mais caro de cada região da base de dados da cidade de Nova York,\n",
    "# apenas para os imóveis disponível para alugar?\n",
    "# R: O diária mais cara no Bronx é de U$ 800\n",
    "# R: O diária mais cara no Brooklyn é de U$ 8000\n",
    "# R: O diária mais cara no Manhattan é de U$ 10000\n",
    "# R: O diária mais cara no Queens é de U$ 2600\n",
    "# R: O diária mais cara no Staten Island é de U$ 625\n",
    "\n",
    "df_grouped = df[['price', 'neighbourhood_group']].groupby( 'neighbourhood_group' )\n",
    "data_plot = df_grouped.max().reset_index()\n",
    "px.bar(data_plot,x = 'neighbourhood_group',y = 'price')\n",
    "\n",
    "# Conseguimos saber onde estão localizados os imóveis com o valor do aluguel mais caro, na cidade de Nova York,\n",
    "# apenas para os imóveis disponível para alugar?\n",
    "f = folium.Figure( width=1024, height=768 )\n",
    "data_plot = df[['price', 'neighbourhood_group', 'latitude', 'longitude']].groupby( ['neighbourhood_group'] ).max().reset_index()\n",
    "map = folium.Map(location=[data_plot['latitude'].mean(),data_plot['longitude'].mean()],zoom_start=14,control_scale=True )\n",
    "\n",
    "for index, location_info in data_plot.iterrows():\n",
    "folium.Marker( [location_info['latitude'], location_info['longitude']],popup=location_info['neighbourhood_group'] ).add_to( map )\n",
    "\n",
    "\n",
    "#Conseguimos saber onde estão localizados os imóveis pelo seu tipo, apenas para os imóveis disponível para alugar?\n",
    "\n",
    "data = df[['neighbourhood_group', 'room_type', 'latitude', 'longitude']].sample(50)\n",
    "data_plot = data.copy()\n",
    "data_plot['color'] = 'NA'\n",
    "map = folium.Map(location=[data_plot['latitude'].mean(),data_plot['longitude'].mean()],zoom_start=14,control_scale=True )\n",
    "data_plot.loc[data_plot['room_type'] == 'Private room', 'color'] = 'darkgreen'\n",
    "data_plot.loc[data_plot['room_type'] == 'Entire home/apt', 'color'] = 'darkred'\n",
    "data_plot.loc[data_plot['room_type'] == 'Shared room', 'color'] = 'purple'\n",
    "\n",
    "for index, location_info in data_plot.iterrows():\n",
    "folium.Marker( [location_info['latitude'], location_info['longitude']],popup=location_info['neighbourhood_group'],icon=folium.Icon( color=location_info['color']), ).add_to( map )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
