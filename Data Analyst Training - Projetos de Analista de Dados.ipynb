{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d98cad",
   "metadata": {},
   "source": [
    "<center><img width=\"25%\" src=\"https://www.camaramirimdoce.sc.gov.br/media/noticia/resumo-da-sessao-10-06-2019-111.png?w=848&h=450&t=P&c=f0f0f0&q=80&v=2\"></center>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "# Data Analyst Training - Projetos de Analista de Dados\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4c81b",
   "metadata": {},
   "source": [
    "# **<u>Sumário:</u>**\n",
    "1. [Por que usar uma estrutura de projeto?](#Por-que-usar-uma-estrutura-de-projeto?)\n",
    "2. [Tipos de Projetos](#Tipos-de-Projetos)\n",
    "3. [Estrutura do Projeto no GitHub](#Estrutura-do-Projeto-no-GitHub)\n",
    "4. [Erros de um projeto](#Erros-de-um-projeto)\n",
    "4. [Etapas da elaboração dos projetos para portifólio](#Etapas-da-elaboração-dos-projetos-para-portifólio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ae4a0",
   "metadata": {},
   "source": [
    "# Por que usar uma estrutura de projeto? \n",
    "[&#x1F53C;](#Sumário:) Clique para voltar para o sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a0890",
   "metadata": {},
   "source": [
    "### Quando pensamos em análise de dados, geralmente pensamos apenas nos relatórios, insights ou visualizações resultantes. Embora esses produtos finais geralmente sejam o evento principal, é fácil se concentrar em fazer com que os produtos tenham uma boa aparência e ignorar a qualidade do código que os gera. E não estamos falando sobre reduzir a estética do recuo ou os padrões de formatação - em última análise, a qualidade do código é sobre correção e reprodutibilidade. <br>\n",
    "### Uma estrutura de projeto padrão e bem definida significa que um novato pode começar a entender uma análise sem se aprofundar em extensa documentação. Isso também significa que eles não precisam necessariamente ler 100% do código antes de saber onde procurar coisas muito específicas. <br>\n",
    "### Já tentou reproduzir uma análise que você fez alguns meses atrás ou mesmo alguns anos atrás? Você pode ter escrito o código, mas agora é impossível decifrar. Criar uma documentação estruturada (Passo a passo) evitará atrasos e erros.\n",
    "<br>\n",
    "\n",
    "### Características principais:\n",
    "* 1 - Iterativo \n",
    "* 2 - Reutilizável e reciclável \n",
    "* 3 - Reproduzível"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7166d98",
   "metadata": {},
   "source": [
    "# Tipos de Projetos\n",
    "[&#x1F53C;](#Sumário:) Clique para voltar para o sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d3f27a",
   "metadata": {},
   "source": [
    "* Um projeto de análise de sentimentos, baseado em um conjunto de dados de texto, como avaliações de produtos, comentários em redes sociais ou opiniões em pesquisas;\n",
    "* Um projeto de análise de série temporal que envolve a identificação de tendências, sazonalidade, flutuações e outras mudanças no comportamento (Datasets Kaggle: djia 30 stock time series);\n",
    "* Um projeto de visualização - Gráfico, Dashboard e Mapas (Interação com o usuário) - Framework: Streamlit, Plotly Dash e Ipywidgets;\n",
    "* Um projeto de análise exploratória de dados, envolvendo coleta e limpeza de dados, visualização, sumarização, identificação de padrões e relacionamentos; \n",
    "* Um projeto de modelagem preditiva, a partir de dados históricos, utilizando análise de regressão, classificação e clusterização (Agrupamento), para prever resultados futuros;\n",
    "* Um projeto de análise de redes sociais que envolve a identificação de tendências, comunidades, influenciadores e outras informações sobre o comportamento; \n",
    "* Um projeto de análise de risco / crédito / financeiro que envolve a análise de fluxo de caixa, rentabilidade e balanços patrimoniais ( Dataset kaggle: Home Credit Default Risk);\n",
    "* Um projeto de análise de dados de vendas que envolve a identificação de padrões de vendas, desempenho de produtos, clientes mais valiosos, entre outros insights importantes para a empresa;\n",
    "* Um projeto de Geo/mapeamento / geoespaciais; \n",
    "* Um projeto de Integração com Bancos de Dados (SQL); \n",
    "* Um projeto de sistemas de recomendação (Dataset Kaggle: Olist, Rees46);\n",
    "* Um projeto de teste A e B e/ou teste de hipótese;\n",
    "* Um projeto de baseado em imagem;\n",
    "\n",
    "### Exemplos:\n",
    "1. Aumente a receita e os lucros: As empresas querem saber como você pode ganhar dinheiro. - Analisar dados de vendas, prever tendências - Previsão de regressão/série temporal mestre - Oferecer ações valiosas para atualizar sua estratégia\n",
    "2. Entenda os clientes As empresas querem saber tudo sobre seus clientes. - Aprenda preferências, hábitos, pontos problemáticos - Pesquise os dados do cliente, identifique padrões - Crie segmentos usando clustering - Personalize campanhas e serviços\n",
    "3. Simplifique as operações As empresas desejam fazer as coisas mais rapidamente. - Lidar com ineficiências - Fornecer soluções baseadas em dados para redução de custos e produtividade - Analisar dados de processo, identificar padrões - Recomendar melhorias impactantes\n",
    "4. Satisfação dos Funcionários Ajude uma empresa a entender seus funcionários. - Analisar os dados de feedback dos funcionários - Identificar áreas de preocupação e melhoria - Implementar estratégias baseadas em dados para uma força de trabalho mais feliz e produtiva\n",
    "5. Supere os concorrentes Mostre a eles o que a concorrência está fazendo. - Avalie as tendências do mercado e o desempenho dos concorrentes - Identifique lacunas e oportunidades de crescimento - Aproveite os dados para criar uma vantagem competitiva\n",
    "\n",
    "<br>\n",
    "\n",
    "Projetos de Análise de Dados com Python\n",
    "Análise da Cadeia de Suprimentos\n",
    "Análise de Demanda e Fornecimento\n",
    "Análise de recessão\n",
    "Análise de Dados do Acelerômetro\n",
    "Análise do funil do usuário\n",
    "Negociação algorítmica\n",
    "Teste A/b\n",
    "Análise da Copa do Mundo T20 2022\n",
    "Linha do tempo do Twitter na análise do mercado de ações\n",
    "Análise de alcance do Instagram\n",
    "Análise de tempo de tela\n",
    "Análise do mercado de ações\n",
    "Análise de dados do smartwatch\n",
    "Análise de Desempenho Virat Kohli\n",
    "Análise de pesquisa do Google\n",
    "Análise de pesquisa\n",
    "Análise do Índice de Progresso Social\n",
    "Análise da Pesquisa de Aspirações de Carreira\n",
    "Análise de Vendas do iPhone\n",
    "Análise de preço de diamante\n",
    "Análise de impactos da Covid-19\n",
    "Análise IPL 2022\n",
    "Ucrânia x Rússia: análise de opinião no Twitter\n",
    "Análise e Previsão de Dicas de Garçom\n",
    "Flipkart Críticas Análise de Sentimentos\n",
    "Análise de Séries Temporais\n",
    "Análise de sentimento de avaliações do TikTok\n",
    "Análise de sentimento de avaliações do Tinder\n",
    "Análise de viagens do Uber\n",
    "Análise de conversas do WhatsApp\n",
    "Análise da qualidade da água\n",
    "Análise de sentimento do jogo Squid\n",
    "Análise de sentimento do Twitter\n",
    "Análise de classificação de filmes para iniciantes\n",
    "Análise Mundial de Bilionários\n",
    "Análise de Desemprego\n",
    "Análise de sentimento de bate-papos do WhatsApp\n",
    "Análise de Vacinas Covid-19\n",
    "Análise de Orçamento Financeiro\n",
    "Melhor Análise de Serviço de Streaming\n",
    "Projeto de ciência de dados sobre análise da taxa de natalidade\n",
    "Projeto de ciência de dados em séries temporais\n",
    "Projeto de ciência de dados sobre área e população\n",
    "Análise de sentimento de análises de produtos da Amazon\n",
    "Análise de sentimento de avaliações de hotéis\n",
    "Análise de sentimento da Google Play Store\n",
    "Análise de alcance do Instagram\n",
    "Amazon Alexa Análise de Sentimentos\n",
    "Análise de sentimento em tempo real\n",
    "Análise da Personalidade do Cliente\n",
    "Análise de dados da Netflix\n",
    "Análise de Sentimento da Vacina Covid-19\n",
    "Análise de coorte\n",
    "> https://amankharwal.medium.com/data-analysis-projects-with-python-a262a6f9e68c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c6a70",
   "metadata": {},
   "source": [
    "# Estrutura do Projeto no GitHub\n",
    "[&#x1F53C;](#Sumário:) Clique para voltar para o sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59512a4",
   "metadata": {},
   "source": [
    "* 1 - Criar uma pasta no computador ou na nuvem \n",
    "* 2 - Criar um repositório no GitHub e inicializa-lo \n",
    "    * a) Criação do arquivo LICENSE (MIT 2.0)\n",
    "    * b) Criação do arquivo README.md \n",
    "    * c) Criação da pasta venv (Com o arquivo .gitignore >>> Este arquivo nunca deve ser confirmado no repositório de controle de versão) \n",
    "* 3 - Criar um ambiente virtual (Virtualenv), caso seja, um projeto que envolva Python\n",
    "    * Criação do arquivo requirements.txt >>> O arquivo de requisitos para reproduzir o ambiente de análise. Gerado escrevendo no terminal: pip freeze > requirements.txt ou pip install -r .\\requirements.txt\n",
    "* 4 - Criar um arquivo com as definições do planejamento do projeto >>> planejamento.txt\n",
    "    * a) Informar os pré-requisitos.\n",
    "    * b) Realizar a decomposição do problema.\n",
    "    * c) Escrever um plano de projeto que estime o impacto, o esforço, os riscos, determine a responsabilidade de cada parte interessada e decide se deve ou não prosseguir com o projeto.\n",
    "    * d) Definir o marcos para etapas intermediárias, um cronograma para atingir cada marco e escrever uma breve descrição de cada etapa.\n",
    "    * e) Informar o produto final\n",
    "    * f) Informar o processo\n",
    "    * g) Informar as ferramentas\n",
    "* 5 - Criar as subpastas que serão utilizadas no projeto (Que foram denifidas no planejamento): \n",
    "    * a) Pasta Dados (Datasets)\n",
    "        * Externo (External) >>> Dados de fontes de terceiros;\n",
    "        * Provisório (Interim ou cache) >>> Dados intermediários que foram transformados. (Muitas vezes, em uma análise, tem etapas de execução longa que pré-processam dados ou treinam modelos. Se essas etapas já foram executadas e suas saídas armazenadas em algum diretório provisório e não deseja esperar para executá-las novamente todas as vezes.);         \n",
    "        * Processados (Processed) >>> Os conjuntos de dados canônicos finais para modelagem;      \n",
    "        * Bruto (Raw) >>> O dados original e imutável;    \n",
    "    * b) Pasta Relatórios (Reports) >>> Análise gerada como HTML, PDF, CSV, etc;\n",
    "        * Gráficos (Plots ou Graphs) >>> Gráficos e números gerados para serem usados em relatórios;\n",
    "        * Imagens (Images) >>> Mídias para serem usadas em relatórios;   \n",
    "        * Pasta Páginas em HTML (Templates) >>> Armazenar as páginas em html criadas;\n",
    "        * Pasta Estático (Static) >>> Códigos em CSS e JavaScript criadas;\n",
    "    * c) Pasta Referência ou Documentos (References ou Docs) >>> Dicionários de dados, Exemplos, Manuais e todos os outros materiais explicativos. (Qualquer documentação sobre a análise)\n",
    "    * d) Pasta Notebooks (SRC) >>> Origem: Código-fonte para uso neste projeto;\n",
    "    * e) Pasta Testes (Tests) >>> Armazenar qualquer caso de teste para as funções criadas (Criação do arquivo teste.py); \n",
    "    * f) Pasta Configuração (Conf) >>> Arquivos de configuração do projeto; \n",
    "    * f) Arquivo credenciais.py >>> Armazenar as senhas/chaves de acessos (.NomeServidorCloud / credentials) \n",
    "        * NomeServidorCloud_Acesso_ID_Chave = MeuAcessoChave \n",
    "        * NomeServidorCloud_Acesso_Secreto_Chave = MinhaChaveSecreta\n",
    "    * g) Arquivo setup.py >>> Torna o projeto pip instalável com \"pip install -e\".       \n",
    "    * h) Arquivo makefiles.txt >>> É um arquivo de texto que contém instruções sobre como criar e vincular (ou compilar) um conjunto de arquivos de código-fonte. \n",
    "* 6 - Criar os arquivos (.py, .ipynb, .pbix e/ou db.sql/.bak) para cada etapa de forma sequencial. Caso seja um projeto com jupyter notebook, a nomenclatura padrão é: < etapa >-< As iniciais do criador >-< descrição >\n",
    "    * a) Criação do arquivo __init__.py (Torna src um módulo Python)\n",
    "    * b) Refatore: Criar um utilitario.py (utility.py), com as principais funções criadas, usadas nos outros notebooks. \n",
    "    * c) Pasta Diagnóstico (Diagnostics) >>> Scripts usados para diagnosticar seus conjuntos de dados\n",
    "        * Notebook_01_fgc_DataCollect (Etapa de coleta de dados)\n",
    "        * Notebook_02_fgc_DataCleaning (Etapa de limpeza de dados)\n",
    "        * Notebook_03_fgc_DataProcessing (Etapa de processamento de dados)       \n",
    "    * d) Pasta Recursos (Features) >>> Scripts para transformar dados brutos em recursos para modelagem \n",
    "        * Criação do arquivo build_features.py\n",
    "        * Notebook_04_fgc_DataPreparationModeling (Etapa de preparação dos dados - modelagem dos dados)\n",
    "    * e) Pasta Modelos (Models) >>> Scripts para treinar modelos e usar modelos treinados e serializados para fazer previsões e resumos de modelo. \n",
    "        * Criação do arquivo predict_model.py  \n",
    "        * Criação do arquivo train_model.py\n",
    "    * f) Pasta Resultados (Results ou Logs) >>> Logs de saída do projeto  \n",
    "        * Notebook_05_fgc_ResultsReadAndAnalysis (Etapa de análise e leitura de resultados)\n",
    "    * g) Pasta Visualização (Visualization) >>> Scripts para criar visualizações exploratórias e orientadas a resultados\n",
    "        * Notebook_06_fgc_DataVisualization (Etapa de visualização de dados)\n",
    "\n",
    "<br> \n",
    "\n",
    "### OBS: Criar um projeto comentado - Foque em explicar \"porque\" tomou as decisões. É mais importante explicar seu raciocício do que ter um modelo com performance absurdamente boa. \n",
    "\n",
    "<br> \n",
    "\n",
    "#### Importar classes e funções entre notebooks: \n",
    "##### a) Instalar (pip install nbimporter) e importar a bibilioteca (import nbimporter)\n",
    "##### b) Importar as funções criadas \n",
    "        \n",
    "        from utilitario/utility import NomeDaFunção\n",
    "<br>         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59396bd",
   "metadata": {},
   "source": [
    "# Erros de um projeto\n",
    "[&#x1F53C;](#Sumário:) Clique para voltar para o sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0181c88",
   "metadata": {},
   "source": [
    "1. Falta de clareza com o objetivo do projeto. <br>\n",
    "2. Não mostrar alguma habilidade do modelo de Machine Learning ou análise de exploração. <br>\n",
    "3. Não saber: Qual o caminho seguir? Qual problema que pretende resolver? Precisa faz uma classificação? Quais técnicas? Quais algoritmos? O que precisa entregar? Quais métricas que o problema exige? <br>\n",
    "4. Não sabe interpretar o que está sendo pedido. <br>\n",
    "5. Tem acesso aos dados? Consegue coletar os dados? Como pode ser feita essa coleta? <br>\n",
    "6. Tem algum baseline que precisa verificar? Pode trazer algum baseline para comparar? Comparou o resultado com o que? <br>\n",
    "7. Dificuldade com fundamentos e conceitos básicos, como: O que é um algoritmo, o que é Machine Learning e quais etapas de um projeto. <br>\n",
    "8. Não sabe o por que escolheu tal técnica? Por que não usou as outras técnicas? Realizou a comparação com outras técnicas? <br>\n",
    "9. Menospreza o processo de limpeza e preparação dos dados. <br>\n",
    "10. Código bagunçado, gráficos ruins e pouca ou nenhuma documentação. <br>\n",
    "11. Não saber avaliar o resultado. <br>\n",
    "12. Ausência dos próximos passos e passos de melhoria. <br>\n",
    "13. Dificuldade no processo de amostragem (Dados enviesados, dados não balanceados, dados distantes da distribuição, não sabe selecionar o conjunto de dados, dados que não reflete a realidade e não sabe separar os dados para treinamento, para teste e para avaliação. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a7f43",
   "metadata": {},
   "source": [
    "# Etapas da elaboração dos projetos para portifólio\n",
    "[&#x1F53C;](#Sumário:) Clique para voltar para o sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feccec7",
   "metadata": {},
   "source": [
    "1. Criação dos repositórios no Github e definição de quais ferramentas e linguagem seriam utilizadas (Python, SQL, Power BI e Excel);  \n",
    "2. Entendimento do problema: a primeira etapa em um projeto de análise de dados é entender claramente o problema que está sendo resolvido. Isso envolve a definição dos objetivos do projeto e a identificação dos principais stakeholders envolvidos. \n",
    "    * a) Criação dos problemas de negócios fictícios, levando em consideração as principais área/setores, departamentos e KPIS de empresas; \n",
    "    * b) Criação de OKRS fictícios com base nos problemas de negócios criados;\n",
    "3. Coleta de dados: uma vez que o problema tenha sido definido, é importante coletar todos os dados relevantes. Isso pode envolver a extração de dados de bancos de dados internos, aquisição de dados de fontes externas, ou a criação de novos conjuntos de dados por meio de experimentos.\n",
    "    * Escolha dos conjuntos de dados de cada projeto;\n",
    "        * Gerador de Banco de Dados > https://www.mockaroo.com/\n",
    "        * Gerador de número > https://www.4devs.com.br/\n",
    "        * https://basedosdados.org/#theme\n",
    "        * https://dados.gov.br/dados/conjuntos-dados\n",
    "        * https://medium.com/programacaodinamica/7-datasets-gratuitos-para-inspirar-seu-portf%C3%B3lio-de-ci%C3%AAncia-de-dados-d6962bea8376\n",
    "        * https://sidra.ibge.gov.br/pesquisa/pia-empresa/quadros/brasil/2021\n",
    "        * https://www.kdnuggets.com/datasets/index.html\n",
    "        * https://learn.microsoft.com/pt-br/power-bi/create-reports/sample-datasets\n",
    "        * https://www.ibge.gov.br/estatisticas/downloads-estatisticas.html\n",
    "        * https://www.datarebel.io/u/TheDataLad\n",
    "        * https://www.dataquest.io/blog/free-datasets-for-projects/\n",
    "4. Criação do projeto junto com o README no Github;\n",
    "    * a) Limpeza e preparação de dados: antes que os dados possam ser analisados, é importante garantir que estejam limpos e preparados para análise. Isso envolve a identificação e correção de valores ausentes ou inconsistentes, a padronização de formatos de dados, e a criação de novas variáveis, se necessário.\n",
    "    * b) Análise exploratória: uma vez que os dados foram limpos e preparados, a próxima etapa é realizar uma análise exploratória dos dados. Isso envolve a criação de visualizações para entender a distribuição dos dados, identificar padrões e tendências, e explorar relações entre diferentes variáveis.\n",
    "    * c) Modelagem de dados: com base na análise exploratória, o próximo passo é criar um modelo de dados que possa ser usado para prever o resultado desejado. Isso pode envolver o uso de técnicas de aprendizado de máquina ou outras técnicas de modelagem estatística.\n",
    "    * d) Validação do modelo: uma vez que o modelo tenha sido criado, é importante validar sua precisão e desempenho. Isso envolve a criação de um conjunto de dados de teste para verificar a precisão do modelo e ajustar os parâmetros, se necessário.\n",
    "    * e) Implantação do modelo: após a validação do modelo, o próximo passo é implementá-lo em um ambiente de produção. Isso pode envolver a criação de uma interface de usuário ou API para permitir que outros usuários acessem o modelo e façam previsões com base em novos dados.\n",
    "    * f) Monitoramento e manutenção: uma vez que o modelo tenha sido implantado, é importante monitorar continuamente seu desempenho e realizar manutenção para garantir que permaneça preciso e eficaz ao longo do tempo.\n",
    "5. Inclusão do projeto no site-portifolio;\n",
    "\n",
    "<br>\n",
    "\n",
    "### Como realizar um projeto de analista de dados tipo End-To-End <br>\n",
    "\n",
    "##### Cite um exemplo: Um projeto de análise de dados end-to-end pode ser a criação de um modelo de recomendação de produtos para uma loja de comércio eletrônico.\n",
    "\n",
    "* A primeira etapa seria entender o problema e os objetivos do projeto, que neste caso seria aumentar as vendas e a satisfação do cliente, oferecendo recomendações de produtos personalizadas.\n",
    "* A segunda etapa seria a coleta de dados, que pode envolver dados de compras anteriores, histórico de navegação do usuário, dados demográficos e outras informações relevantes.\n",
    "* A terceira etapa seria a limpeza e preparação dos dados, que envolveria a remoção de valores ausentes, a padronização de formatos de dados e a criação de novas variáveis, como histórico de compras e itens visualizados.\n",
    "* A quarta etapa seria a análise exploratória, que envolveria a criação de visualizações para entender a distribuição dos dados e identificar padrões e tendências.\n",
    "* A quinta etapa seria a modelagem de dados, que pode envolver a utilização de algoritmos de aprendizado de máquina, como filtros colaborativos ou modelos baseados em conteúdo.\n",
    "* A sexta etapa seria a validação do modelo, que envolveria a criação de um conjunto de dados de teste para verificar a precisão do modelo e ajustar os parâmetros, se necessário.\n",
    "* A sétima etapa seria a implantação do modelo, que pode envolver a criação de uma interface de usuário ou API para permitir que os usuários acessem o modelo e recebam recomendações personalizadas.\n",
    "* A oitava etapa seria o monitoramento e manutenção do modelo, que envolveria a monitoração do desempenho do modelo e a realização de manutenção regular para garantir que o modelo permaneça preciso e eficaz ao longo do tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1882b28",
   "metadata": {},
   "source": [
    "# Versão 1.1 (30/03/2023)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
